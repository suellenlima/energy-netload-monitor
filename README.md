Run Docker

docker-compose up --build


Abra http://localhost:5050.

Login: admin@energy.com / Senha: admin.


Execute

docker-compose exec db psql -U admin -d energy_monitor

docker-compose exec etl python src/extractors/aneel_client.py
docker-compose exec etl python src/extractors/ons_client.py
docker-compose exec etl python src/extractors/gd_client.py
docker-compose exec etl python src/extractors/inpe_weather_client.py




energy-netload-monitor/
â”œâ”€â”€ .github/                 # CI/CD (GitHub Actions para deploy/testes)
â”œâ”€â”€ .gitignore               # Ignorar venv, dados locais, credenciais
â”œâ”€â”€ docker-compose.yml       # Orquestra todos os containers (DB, API, Airflow)
â”œâ”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ .env.example             # Exemplo de variÃ¡veis de ambiente (DB_HOST, API_KEY)
â”‚
â”œâ”€â”€ ğŸ“‚ infrastructure/       # ConfiguraÃ§Ãµes de Infraestrutura (IaC)
â”‚   â”œâ”€â”€ ğŸ“‚ database/         # Scripts de inicializaÃ§Ã£o do DB
â”‚   â”‚   â”œâ”€â”€ init_postgis.sh  # Script para ativar extensÃ£o PostGIS
â”‚   â”‚   â””â”€â”€ schema.sql       # DDL das tabelas (Carga, Usinas, SatÃ©lite)
â”‚   â””â”€â”€ ğŸ“‚ airflow/          # ConfiguraÃ§Ãµes do Apache Airflow (se usado)
â”‚
â”œâ”€â”€ ğŸ“‚ data/                 # Armazenamento local temporÃ¡rio (Ignorado no Git)
â”‚   â”œâ”€â”€ ğŸ“‚ raw/              # CSVs baixados do ONS/ANEEL
â”‚   â”œâ”€â”€ ğŸ“‚ processed/        # Dados limpos prontos para o banco
â”‚   â””â”€â”€ ğŸ“‚ images/           # Tiles de satÃ©lite do INPE
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/            # Ãrea de "Playground" para Cientistas de Dados
â”‚   â”œâ”€â”€ 01_exploracao_ons.ipynb
â”‚   â”œâ”€â”€ 02_validacao_siga.ipynb
â”‚   â””â”€â”€ 03_treino_modelo_telhados.ipynb
â”‚
â”œâ”€â”€ ğŸ“‚ backend/              # LÃ³gica da AplicaÃ§Ã£o e API (FastAPI)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt     # DependÃªncias Python
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ main.py          # Entrypoint da API
â”‚       â”œâ”€â”€ ğŸ“‚ api/          # Rotas/Endpoints (ex: /get-hidden-load)
â”‚       â”œâ”€â”€ ğŸ“‚ core/         # ConfiguraÃ§Ãµes globais (Settings)
â”‚       â”œâ”€â”€ ğŸ“‚ domain/       # Modelos de Dados (Pydantic/SQLAlchemy)
â”‚       â””â”€â”€ ğŸ“‚ services/     # LÃ³gica de NegÃ³cio (O "CÃ©rebro")
â”‚           â”œâ”€â”€ geospatial.py # Cruzamento de coordenadas (PostGIS logic)
â”‚           â””â”€â”€ load_calc.py  # CÃ¡lculo de Carga LÃ­quida vs Real
â”‚
â”œâ”€â”€ ğŸ“‚ etl_pipeline/         # Engenharia de Dados (Workers)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ ğŸ“‚ extractors/   # Scripts que baixam dados
â”‚       â”‚   â”œâ”€â”€ aneel_client.py
â”‚       â”‚   â”œâ”€â”€ ons_client.py
â”‚       â”‚   â””â”€â”€ inpe_client.py
â”‚       â”œâ”€â”€ ğŸ“‚ transformers/ # Limpeza e normalizaÃ§Ã£o (Pandas/GeoPandas)
â”‚       â””â”€â”€ ğŸ“‚ loaders/      # InserÃ§Ã£o no PostgreSQL
â”‚
â””â”€â”€ ğŸ“‚ frontend/             # Interface do UsuÃ¡rio (React/Streamlit)
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ package.json
    â”œâ”€â”€ public/
    â””â”€â”€ src/
        â”œâ”€â”€ ğŸ“‚ components/   # Mapa, GrÃ¡ficos, BotÃµes
        â””â”€â”€ ğŸ“‚ services/     # ConexÃ£o com o backend (API Client)


1. SeparaÃ§Ã£o de "Prototipagem" e "ProduÃ§Ã£o"
Problema: Ã‰ comum misturar Jupyter Notebooks com cÃ³digo de produÃ§Ã£o.

SoluÃ§Ã£o: A pasta notebooks/ Ã© onde vocÃª testa hipÃ³teses e visualiza os dados do INPE/ONS pela primeira vez. Quando o cÃ³digo funciona, vocÃª o refatora e move para etl_pipeline/ ou backend/src/services.

2. Isolamento do Pipeline de Dados (etl_pipeline/)
Os scripts que baixam dados da ANEEL e ONS nÃ£o devem estar dentro da API. Eles sÃ£o processos demorados (background jobs).

Ao separÃ¡-los, vocÃª pode escalar o ETL independentemente da API. Se precisar processar 10 anos de histÃ³rico do ONS, isso nÃ£o vai derrubar o site que o usuÃ¡rio estÃ¡ acessando.

3. CentralizaÃ§Ã£o da Infraestrutura (infrastructure/)
Aqui ficam os scripts SQL que criam as tabelas e ativam o PostGIS. Isso Ã© crucial para que, se vocÃª apagar tudo e rodar docker-compose up, o ambiente se reconstrua sozinho e pronto para uso.

4. Dados Locais (data/)
Regra de Ouro: Nunca suba dados (CSVs ou Imagens) para o GitHub.

Esta pasta serve como um "cache" local para seus scripts Python. O .gitignore deve garantir que ela nÃ£o seja versionada, evitando repositÃ³rios pesados.


Boas PrÃ¡ticas Embutidas

ModularizaÃ§Ã£o: Se a ANEEL mudar o link do arquivo CSV, vocÃª sÃ³ precisa alterar etl_pipeline/src/extractors/aneel_client.py. O resto do sistema nem percebe.

ContainerizaÃ§Ã£o: Note que backend, frontend e etl_pipeline tÃªm seus prÃ³prios Dockerfiles. Isso evita o inferno de dependÃªncias (ex: o GeoPandas do ETL nÃ£o conflita com o Pandas da API).

Domain-Driven Design (DDD) Lite: Na pasta backend/src/services, temos geospatial.py. Ali deve conter apenas a lÃ³gica pura de como cruzar mapas, sem se preocupar se o dado veio de uma API ou de um CSV.




Carga Oculta Total = Estimativa ANEEL (Oficial) + Fraudes Detectadas (IA)

